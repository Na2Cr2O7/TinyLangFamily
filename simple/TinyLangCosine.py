import json
import os
import math
from typing import List
from time import time
import sqlite3

if not os.path.exists('../dataset.db'):
    import compressDatasetSqlite

import dbconnect
questions, answers = dbconnect.questions, dbconnect.answers

# â€”â€”â€”â€”â€”â€” Step 1: æ„å»ºæˆ–åŠ è½½ tokenizerï¼ˆchar â†’ indexï¼‰â€”â€”â€”â€”â€”â€”
if not os.path.exists('tokenizer.json'):
    import wordFrequency
    freq_list = wordFrequency.frequency_as_string(questions+answers)
    # æŒ‰ frequency ä¸­çš„é¡ºåºå»ºç«‹æ˜ å°„ï¼ˆé«˜é¢‘åœ¨å‰ï¼Œä½†ä¸å½±å“ correctnessï¼‰
    start=time()
    chartoidx = {char: idx for idx, (char, _) in enumerate(freq_list)}
    print(f"âœ… æ„å»º tokenizer.json è€—æ—¶:{time()-start:.2f}s")
    with open('tokenizer.json', 'w', encoding='utf8') as f:
        json.dump(chartoidx, f, ensure_ascii=False)
else:
    with open('tokenizer.json', 'r', encoding='utf8') as f:
        chartoidx = json.load(f)

start=time()
vocab_size = len(chartoidx)






# â€”â€”â€”â€”â€”â€” Step 3: æ–‡æœ¬ â†’ å›ºå®šç»´åº¦é¢‘æ¬¡å‘é‡ â€”â€”â€”â€”â€”â€”
def text_to_vector(text: str,seq_len=16) -> List[int]:
    vec = [0] * vocab_size
    for char in text:
        if char in chartoidx:
            idx = chartoidx[char]
            vec[idx] += 1  # è®¡æ•°ï¼šTerm Frequency
    
    return vec

# é¢„è®¡ç®—æ‰€æœ‰é—®é¢˜çš„å‘é‡ï¼ˆå¤§å¹…æå‡æŸ¥è¯¢é€Ÿåº¦ï¼‰
print("æ­£åœ¨é¢„è®¡ç®—é—®é¢˜å‘é‡...")

question_vectors = [text_to_vector(q) for q in questions]

print(f"âœ… åŠ è½½ {len(questions)} ä¸ªé—®é¢˜ï¼Œè¯è¡¨å¤§å°: {vocab_size}")

# â€”â€”â€”â€”â€”â€” Step 4: ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆçº¯ mathï¼‰â€”â€”â€”â€”â€”â€”
def cosine_similarity(v1: List[int], v2: List[int]) -> float:
    dot = 0
    norm1_sq = 0
    norm2_sq = 0
    for a, b in zip(v1, v2):
        dot += a * b
        norm1_sq += a * a
        norm2_sq += b * b
    if norm1_sq == 0 or norm2_sq == 0:
        return 0.0
    return dot / (math.sqrt(norm1_sq) * math.sqrt(norm2_sq))

# â€”â€”â€”â€”â€”â€” Step 5: é—®ç­”ä¸»å‡½æ•° â€”â€”â€”â€”â€”â€”
def answer_fast(user_question: str) -> str:
    if not user_question.strip():
        return "è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜ã€‚"
    
    user_vec = text_to_vector(user_question)
    best_idx = 0
    max_sim = -1.0

    for i, q_vec in enumerate(question_vectors):
        sim = cosine_similarity(user_vec, q_vec)
        if sim > max_sim:
            max_sim = sim
            best_idx = i

    # å¯é€‰ï¼šè®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼é¿å…ä½è´¨é‡åŒ¹é…
    if max_sim < 0.1:
        return "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªæ˜ç™½ä½ çš„æ„æ€ã€‚"
    
    return answers[best_idx]


print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶:{time()-start:.2f}s")

# â€”â€”â€”â€”â€”â€” ä¸»ç¨‹åº â€”â€”â€”â€”â€”â€”
if __name__ == '__main__':
    print('TinyLangCosine-Sqlite æµ‹è¯•')
    print('æ•°æ®é›†:https://modelscope.cn/datasets/qiaojiedongfeng/qiaojiedongfeng')
    try:
        while True:
            q = input('è¯·è¾“å…¥é—®é¢˜: ')
            start=time()
            print("â†’", answer_fast(q))
            print(f"âœ… è€—æ—¶:{time()-start:.2f}s")
    except (KeyboardInterrupt, EOFError):
        print("\nğŸ‘‹ å†è§ï¼")